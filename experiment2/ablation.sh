# Ensure experiment-scoped paths exist
CACHE_BACKEND="${CACHE_BACKEND:-model-router}"
CACHE_MODE="${CACHE_MODE:-dry-run}"
GQA_IMAGE_DIR="${GQA_IMAGE_DIR:-experiment2/gqa_images}"
CACHE_MAX_SIZE_GB="${CACHE_MAX_SIZE_GB:-64}"
CACHE_SIZE_FLAG="--cache-max-size-gb ${CACHE_MAX_SIZE_GB}"
# Set GPU to use (default to GPU 0 if not specified)
export CUDA_VISIBLE_DEVICES="${CUDA_VISIBLE_DEVICES:-0}"
# Using Hugging Face transformers instead of vLLM to avoid multimodal cache bugs
mkdir -p experiment2/experiment_logs/ablation_samples "${GQA_IMAGE_DIR}"

# qwen-exact-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-exact-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-exact-only --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-exact-only.jsonl --use-hf

# qwen-fusion-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-fusion-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-fusion-only --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --enable-fusion-cache --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-fusion-only.jsonl --use-hf

# qwen-semantic-0.5
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.5 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.5 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.5 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.5.jsonl --use-hf

# qwen-semantic-0.6
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.6 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.6 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.6 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.6.jsonl --use-hf

# qwen-semantic-0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.7 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.7.jsonl --use-hf

# qwen-semantic-0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.8.jsonl --use-hf

# qwen-semantic-0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.9 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.9.jsonl --use-hf

# qwen-embed-p0.7-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.7.jsonl --use-hf

# qwen-embed-p0.7-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.8.jsonl --use-hf

# qwen-embed-p0.7-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.9.jsonl --use-hf

# qwen-embed-p0.8-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.7.jsonl --use-hf

# qwen-embed-p0.8-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.8.jsonl --use-hf

# qwen-embed-p0.8-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.9.jsonl --use-hf

# qwen-embed-p0.9-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# qwen-embed-p0.9-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# qwen-embed-p0.9-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# Experimental
# # qwen-native-enc0.7 (Native VLM embeddings: text=2048d + vision=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-enc0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-enc0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:2048:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-enc0.7.jsonl --use-hf

# # qwen-native-enc0.8 (Native VLM embeddings: text=2048d + vision=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-enc0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-enc0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:2048:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-enc0.8.jsonl --use-hf

# # qwen-native-enc0.9 (Native VLM embeddings: text=2048d + vision=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-enc0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-enc0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:2048:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-enc0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # qwen-native-t0.7-v0.8 (text threshold=0.7, vision threshold=0.8)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.7-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:2048:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.7-v0.8.jsonl --use-hf

# # qwen-native-t0.7-v0.9 (text threshold=0.7, vision threshold=0.9)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.7-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:2048:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.7-v0.9.jsonl --use-hf

# # qwen-native-t0.8-v0.7 (text threshold=0.8, vision threshold=0.7)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.8-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:2048:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.8-v0.7.jsonl --use-hf

# # qwen-native-t0.8-v0.9 (text threshold=0.8, vision threshold=0.9)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.8-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:2048:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.8-v0.9.jsonl --use-hf

# # qwen-native-t0.9-v0.7 (text threshold=0.9, vision threshold=0.7)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.9-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:2048:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.9-v0.7.jsonl --use-hf

# # qwen-native-t0.9-v0.8 (text threshold=0.9, vision threshold=0.8)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-native-t0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-native-t0.9-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:2048:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-backend "${CACHE_BACKEND}" --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-native-t0.9-v0.8.jsonl --use-hf

# internvl-exact-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-exact-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-exact-only --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-exact-only.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-fusion-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-fusion-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-fusion-only --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --enable-fusion-cache --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-fusion-only.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-semantic-0.5
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.5 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.5 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.5 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.5.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-semantic-0.6
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.6 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.6 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.6 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.6.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-semantic-0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.7 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-semantic-0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-semantic-0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.9 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.7-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.7-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.7-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.8-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.8-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.8-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.9-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.9-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# internvl-embed-p0.9-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

## Experimental
# # internvl-native-enc0.7 (Native VLM embeddings: encoder=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-enc0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-enc0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:1024:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-enc0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-enc0.8 (Native VLM embeddings: encoder=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-enc0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-enc0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:1024:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-enc0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-enc0.9 (Native VLM embeddings: encoder=2048d)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-enc0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-enc0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:1024:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-enc0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.7-v0.8 (text threshold=0.7, vision threshold=0.8)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.7-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:1024:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.7-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.7-v0.9 (text threshold=0.7, vision threshold=0.9)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.7-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.7 --embedding-layer native_encoder:1024:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.7-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.8-v0.7 (text threshold=0.8, vision threshold=0.7)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.8-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:1024:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.8-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.8-v0.9 (text threshold=0.8, vision threshold=0.9)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.8-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.8 --embedding-layer native_encoder:1024:0.9 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.8-v0.9.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.9-v0.7 (text threshold=0.9, vision threshold=0.7)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.9-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:1024:0.7 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.9-v0.7.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf

# # internvl-native-t0.9-v0.8 (text threshold=0.9, vision threshold=0.8)
# rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-native-t0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-native-t0.9-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
# You are assisting with the GQA benchmark. Answer the question using the referenced image.
# Image ID: {image_id}
# Question: {question}
# Answer:' --similarity-threshold 0.8 --embedding-layer native_text:2048:0.9 --embedding-layer native_encoder:1024:0.8 --embedding-hook native_text_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --gqa-image-dir "${GQA_IMAGE_DIR}" --disable-semantic-cache --disable-exact-cache --trust-remote-code ${CACHE_SIZE_FLAG} --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-native-t0.9-v0.8.jsonl --cache-backend "${CACHE_BACKEND}" --use-hf
