CACHE_MODE=live python experiment2/test_vllm.py   --model Qwen/Qwen3-VL-2B-Instruct   --dataset gqa   --dataset-config val_balanced_instructions   --split val   --max-samples 256   --chunk-source semantic   --similarity-threshold 0.8   --cache-dir experiment2/kv_chunks_live   --cache-max-size-gb 10   --fusion-cache-dir experiment2/fusion_chunks_live   --enable-fusion-cache   --embedding-layer prompt:384:0.8   --embedding-layer vision:512:0.8   --embedding-hook prompt_vision   --temperature 0.0   --max-tokens 64   --tensor-parallel-size 1   --gpu-memory-utilization 0.9   --cache-mode ^Cve   --trust-remote-code