# Ensure experiment-scoped paths exist
CACHE_MODE="${CACHE_MODE:-dry-run}"
mkdir -p experiment2/experiment_logs/ablation_samples

# qwen-exact-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-exact-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-exact-only --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-exact-only.jsonl

# qwen-fusion-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-fusion-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-fusion-only --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --enable-fusion-cache --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-fusion-only.jsonl

# qwen-semantic-0.5
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.5 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.5 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.5 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.5.jsonl

# qwen-semantic-0.6
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.6 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.6 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.6 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.6.jsonl

# qwen-semantic-0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.7 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.7.jsonl

# qwen-semantic-0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.8.jsonl

# qwen-semantic-0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-semantic-0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-semantic-0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.9 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-semantic-0.9.jsonl

# qwen-embed-p0.7-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.7.jsonl

# qwen-embed-p0.7-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.8.jsonl

# qwen-embed-p0.7-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.7-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.7-v0.9.jsonl

# qwen-embed-p0.8-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.7.jsonl

# qwen-embed-p0.8-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.8.jsonl

# qwen-embed-p0.8-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.8-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.8-v0.9.jsonl

# qwen-embed-p0.9-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.7 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.7.jsonl

# qwen-embed-p0.9-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.8 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.8.jsonl

# qwen-embed-p0.9-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== qwen-embed-p0.9-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name qwen-embed-p0.9-v0.9 --model Qwen/Qwen3-VL-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/qwen-embed-p0.9-v0.9.jsonl

# internvl-exact-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-exact-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-exact-only --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-exact-only.jsonl

# internvl-fusion-only
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-fusion-only ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-fusion-only --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --enable-fusion-cache --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-fusion-only.jsonl

# internvl-semantic-0.5
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.5 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.5 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.5 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.5.jsonl

# internvl-semantic-0.6
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.6 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.6 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.6 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.6.jsonl

# internvl-semantic-0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.7 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.7.jsonl

# internvl-semantic-0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.8.jsonl

# internvl-semantic-0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-semantic-0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-semantic-0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.9 --embedding-hook none --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-semantic-0.9.jsonl

# internvl-embed-p0.7-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.7.jsonl

# internvl-embed-p0.7-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.8.jsonl

# internvl-embed-p0.7-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.7-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.7-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.7 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.7-v0.9.jsonl

# internvl-embed-p0.8-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.7.jsonl

# internvl-embed-p0.8-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.8.jsonl

# internvl-embed-p0.8-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.8-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.8-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.8 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.8-v0.9.jsonl

# internvl-embed-p0.9-v0.7
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.7 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.7 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.7 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.7.jsonl

# internvl-embed-p0.9-v0.8
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.8 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.8 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.8 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.8.jsonl

# internvl-embed-p0.9-v0.9
rm -rf experiment2/fusion_chunks_ablation && rm -rf experiment2/kv_chunks_ablation && echo "=== internvl-embed-p0.9-v0.9 ===" && CUDA_LAUNCH_BLOCKING=1 python experiment2/test_vllm.py --experiment-name internvl-embed-p0.9-v0.9 --model OpenGVLab/InternVL3_5-2B-Instruct --dataset gqa --dataset-config val_balanced_instructions --split val --max-samples 1024 --shuffle-seed 42 --chunk-source semantic --prompt-template '<image>
You are assisting with the GQA benchmark. Answer the question using the referenced image.
Image ID: {image_id}
Question: {question}
Answer:' --similarity-threshold 0.8 --embedding-layer prompt:384:0.9 --embedding-layer vision:512:0.9 --embedding-hook prompt_vision --cache-dir experiment2/kv_chunks_ablation --index-encoder sentence-transformers/all-MiniLM-L6-v2 --index-encoder-device cuda --fusion-cache-dir experiment2/fusion_chunks_ablation --temperature 0.0 --max-tokens 64 --tensor-parallel-size 1 --gpu-memory-utilization 0.9 --cache-mode "${CACHE_MODE}" --disable-semantic-cache --disable-exact-cache --trust-remote-code --summary-log experiment2/experiment_logs/ablation_results.csv --samples-jsonl experiment2/experiment_logs/ablation_samples/internvl-embed-p0.9-v0.9.jsonl
